{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ASC Accelerometer analysis via Summary Statistics \r\n",
    "\r\n",
    "FDeveloping moving average acceleration and moving Standard Deviation for each data set.\r\n",
    "\r\n",
    "Can run through a whole folder, or through random selections from the folder\r\n",
    "\r\n",
    "## This is attempting a slicker method using matrix multiplication.  With that can then attempt GPU parallelization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Standard Header used on the projects\r\n",
    "\r\n",
    "#first the major packages used for math and graphing\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from cycler import cycler\r\n",
    "import scipy.special as sp\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "#Custome graph format style sheet\r\n",
    "plt.style.use('Prospectus.mplstyle')\r\n",
    "\r\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\r\n",
    "#otherwise set what is needed\r\n",
    "if not 'Saving' in locals():\r\n",
    "    Saving = False\r\n",
    "if not 'Titles' in locals():\r\n",
    "    Titles = True\r\n",
    "if not 'Ledgends' in locals():\r\n",
    "    Ledgends = True\r\n",
    "if not 'FFormat' in locals():\r\n",
    "    FFormat = '.png'\r\n",
    "if not 'location' in locals():\r\n",
    "    #save location.  First one is for running on home PC, second for running on the work laptop.  May need to make a global change\r\n",
    "    #location = 'E:\\\\Documents\\\\Dan\\\\Code\\\\Prospectus\\\\Document\\\\Figures\\\\'\r\n",
    "    #location = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\github\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\r\n",
    "    location = 'E:\\\\Documents\\\\Dan\\\\Phd\\\\Play\\\\'\r\n",
    "\r\n",
    "#Standard cycle for collors and line styles\r\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\r\n",
    "plt.rc('axes', prop_cycle=default_cycler)\r\n",
    "my_cmap = plt.get_cmap('gray')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Extra Headers:\r\n",
    "import os as os\r\n",
    "import statistics as st\r\n",
    "import os as os\r\n",
    "import pandas as pd\r\n",
    "import random\r\n",
    "import multiprocessing\r\n",
    "from joblib import Parallel, delayed\r\n",
    "import time\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Columns names for a file with all 6 dimmensions\r\n",
    "Header = np.array(['T', 'X','Y','Z','R','Theta','Phi'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#opens all files in a folder and returns the 3 axis acceleration in one array\r\n",
    "# made to run in parallel\r\n",
    "\r\n",
    "def getAcceleration(FileName):\r\n",
    "    try:\r\n",
    "        DataSet = np.genfromtxt(open(FileName,'r'), delimiter=',',skip_header=0)\r\n",
    "        if FileName[64:69] == 'Accel':\r\n",
    "            return [[FileName[61:],'x',DataSet[:,2]],[FileName[61:],'y',DataSet[:,3]],[FileName[61:],'z',DataSet[:,4]]]\r\n",
    "        else:\r\n",
    "            return [False,FileName,False]\r\n",
    "    except:\r\n",
    "        return [False,FileName,False]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#first attempt at making stats by brute force, very slow\r\n",
    "def makeStats(DataArray):\r\n",
    "    try:\r\n",
    "        Arange = 50\r\n",
    "        length = np.shape(DataArray[2])[0]\r\n",
    "        StdDev = np.zeros(length)\r\n",
    "        for j in range(length-Arange):\r\n",
    "            k = (length-1)-j\r\n",
    "            DataArray[2][k] = np.average(DataArray[2][k-Arange:k])\r\n",
    "            StdDev[k]=st.stdev(DataArray[2][k-Arange:k])\r\n",
    "        return [DataArray[0],DataArray[1],max(DataArray[2]),max(StdDev)]\r\n",
    "    except:\r\n",
    "        return ['','','','']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Uses matrixes and numpy to calculate the standard deviations of each row simultaneously.\r\n",
    "# designed to run each time step independently\r\n",
    "# can be run in parallel\r\n",
    "\r\n",
    "def MatStdDev(MoveMatrix, AvgVector):\r\n",
    "    width = np.shape(MoveMatrix)[1]\r\n",
    "\r\n",
    "    AvgMatrix = np.concatenate((AvgVector,AvgVector),axis=1)\r\n",
    "    for i in range(width-2):\r\n",
    "        AvgMatrix = np.concatenate((AvgMatrix,AvgVector),axis=1)\r\n",
    "    AvgVector = []\r\n",
    "\r\n",
    "    Deltas = MoveMatrix - AvgMatrix\r\n",
    "    AvgMatrix = []\r\n",
    "    MoveMatrix = []\r\n",
    "\r\n",
    "    SquareDifference = np.power(Deltas,2)\r\n",
    "    Deltas = []\r\n",
    "\r\n",
    "    one = np.ones((width))\r\n",
    "\r\n",
    "    SumSquares = SquareDifference.dot(one)\r\n",
    "    SquareDifference = []\r\n",
    "\r\n",
    "    StdDev = np.power(SumSquares, 0.5)/ width\r\n",
    "    SumSquares = {}\r\n",
    "\r\n",
    "    return StdDev"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Inputs:\r\n",
    "folder1 = 'C:\\\\Users\\\\Hendrickson\\\\Desktop\\\\Phone Acceleration\\\\'\r\n",
    "folder2 = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\r\n",
    "\r\n",
    "files = os.listdir(folder2)\r\n",
    "\r\n",
    "Groups = 0\r\n",
    "GroupSize = 100\r\n",
    "\r\n",
    "RollingSize = 50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Pre Calculations\r\n",
    "\r\n",
    "num_cores = multiprocessing.cpu_count()\r\n",
    "if np.shape(files)[0] < GroupSize:\r\n",
    "    GroupSize = np.shape(files)[0]\r\n",
    "\r\n",
    "if Groups !=0:\r\n",
    "    files = random.sample(files,GroupSize*Groups-1)\r\n",
    "\r\n",
    "loops = int(float(np.size(files))/float(GroupSize))+1\r\n",
    "start = time.time()\r\n",
    "\r\n",
    "inverseRollingSize = 1 / RollingSize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    AllEvents=[]\r\n",
    "    Fails = []\r\n",
    "    for i in range(loops):\r\n",
    "        \r\n",
    "        AllAccels = Parallel(n_jobs=num_cores)(delayed(getAcceleration)(folder2+file) for file in files[i*GroupSize:((i+1)*GroupSize)])\r\n",
    "        MetaData = []\r\n",
    "        DataOnlyMatrix = []\r\n",
    "        for j in range(np.shape(AllAccels)[0]):\r\n",
    "            if AllAccels[j][0] == False :\r\n",
    "                if AllAccels[j][1][4:9] =='Accel':\r\n",
    "                    print(j,AllAccels[j][1])\r\n",
    "            else: \r\n",
    "                for k in range(3):\r\n",
    "                    MetaData.append([AllAccels[j][k][0], AllAccels[j][k][1]])\r\n",
    "                    if np.shape(np.matrix(AllAccels[j][k][2]))[1] < 60000:\r\n",
    "                        temp = np.pad(np.matrix(AllAccels[j][k][2]),(60000-np.shape(np.matrix(AllAccels[j][k][2]))[1],0))[0]\r\n",
    "                        if DataOnlyMatrix == []:\r\n",
    "                            DataOnlyMatrix =np.matrix(temp)\r\n",
    "                        else:\r\n",
    "                            DataOnlyMatrix = np.concatenate((DataOnlyMatrix,temp),axis=1)\r\n",
    "                    if DataOnlyMatrix == []:\r\n",
    "                        DataOnlyMatrix =np.matrix(AllAccels[j][k][2])\r\n",
    "                    else:\r\n",
    "                        DataOnlyMatrix = np.concatenate((DataOnlyMatrix,np.matrix(AllAccels[j][k][2])),axis=0)\r\n",
    "        \r\n",
    "        DataOnlyMatrix = np.matrix(DataOnlyMatrix)\r\n",
    "        \r\n",
    "        length = np.shape(DataOnlyMatrix)[1]\r\n",
    "        halfLength = int(length / 2)\r\n",
    "        \r\n",
    "        Weights1 = np.zeros((halfLength,halfLength))\r\n",
    "        Weights2 = np.zeros((halfLength,halfLength+RollingSize-1))\r\n",
    "                \r\n",
    "        for j in range(halfLength):\r\n",
    "            r = j+1\r\n",
    "            \r\n",
    "            if r < RollingSize:\r\n",
    "               ir = 1/ r\r\n",
    "               for k in range(r):\r\n",
    "                    Weights1[k,j] = ir\r\n",
    "            else:\r\n",
    "                for k in range(RollingSize):\r\n",
    "                    Weights1[r-RollingSize+k, j] = inverseRollingSize\r\n",
    "            for k in range(RollingSize):\r\n",
    "                Weights2[j,j+k] = inverseRollingSize\r\n",
    "                \r\n",
    "        FirstBit = np.dot(DataOnlyMatrix[:,:halfLength], Weights1)\r\n",
    "        Weights1 = []\r\n",
    "\r\n",
    "        if length % 2 == 1: halfLength += 1\r\n",
    "        Weights2=Weights2[:,:halfLength]\r\n",
    "        SecondBit = np.dot(DataOnlyMatrix[:,halfLength:], Weights2)\r\n",
    "        \r\n",
    "        Weights2 = [] \r\n",
    "\r\n",
    "        Weights3 = np.zeros((halfLength,halfLength))\r\n",
    "        for j in range(RollingSize-1):\r\n",
    "            for k in range(RollingSize-j-1):\r\n",
    "                Weights3[halfLength-k-1,j] = inverseRollingSize\r\n",
    "\r\n",
    "        SecondBit = SecondBit + np.dot(DataOnlyMatrix[:,halfLength:], Weights3)\r\n",
    "        Weights3 = []\r\n",
    "\r\n",
    "        Averages = np.concatenate((FirstBit, SecondBit), axis=1)\r\n",
    "        FirstBit = []\r\n",
    "        SecondBit = []\r\n",
    "        \r\n",
    "        # Calculating the Standard Devation by square\r\n",
    "        AllStdDevs = Parallel(n_jobs=num_cores)(delayed(MatStdDev)(DataOnlyMatrix[:,i:RollingSize+i],Averages[:,RollingSize+i] ) for i in range(length-RollingSize))\r\n",
    "        AllStdDevs=np.squeeze(AllStdDevs)\r\n",
    "        AllStdDevs = np.concatenate( (np.zeros((RollingSize,np.shape(AllStdDevs)[1])), AllStdDevs),axis=0)\r\n",
    "\r\n",
    "        one = np.ones((length))\r\n",
    "        AvgVector = Averages.dot(one)\r\n",
    "        Averages = []\r\n",
    "        \r\n",
    "        AllStdDevs = np.transpose(AllStdDevs)\r\n",
    "        StdDevVector = AllStdDevs.dot(one)\r\n",
    "        AllStdDevs = []\r\n",
    "\r\n",
    "        if AllEvents == []:\r\n",
    "            temp = np.concatenate((MetaData, AvgVector.transpose()), axis=1)\r\n",
    "            AllEvents = np.concatenate((temp, np.matrix(StdDevVector).transpose()),axis = 1)\r\n",
    "        else:\r\n",
    "            temp = np.concatenate((MetaData, AvgVector.transpose()), axis=1)\r\n",
    "            temp = np.concatenate((temp, np.matrix(StdDevVector).transpose()),axis = 1)\r\n",
    "            AllEvents = np.concatenate((AllEvents,temp),axis=0)\r\n",
    "            temp=[]\r\n",
    "        print('Loop ' + str(i+1) + ' of ' + str(loops) + '.  Total time is ' + str((time.time() - start) / 60) + ' min')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<ipython-input-13-db7cd0d32ee6>:22: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if DataOnlyMatrix == []:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loop 0 of 106.  Total time is 1.7866789102554321min\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-13-db7cd0d32ee6>:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if AllEvents == []:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loop 1 of 106.  Total time is 2.439117801189423min\n",
      "Loop 2 of 106.  Total time is 3.093441613515218min\n",
      "Loop 3 of 106.  Total time is 3.7243566870689393min\n",
      "Loop 4 of 106.  Total time is 4.37751609881719min\n",
      "Loop 5 of 106.  Total time is 4.995495915412903min\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(data=AllEvents)\r\n",
    "df.to_csv(folder1 + 'StatisticsReport.csv', sep=',', index = False, header=False,quotechar='\"')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
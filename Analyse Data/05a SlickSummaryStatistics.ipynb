{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ASC Accelerometer analysis via Summary Statistics \r\n",
    "\r\n",
    "FDeveloping moving average acceleration and moving Standard Deviation for each data set.\r\n",
    "\r\n",
    "Can run through a whole folder, or through random selections from the folder\r\n",
    "\r\n",
    "## This is attempting a slicker method using matrix multiplication.  With that can then attempt GPU parallelization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Standard Header used on the projects\r\n",
    "\r\n",
    "#first the major packages used for math and graphing\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from cycler import cycler\r\n",
    "import scipy.special as sp\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "#Custome graph format style sheet\r\n",
    "plt.style.use('Prospectus.mplstyle')\r\n",
    "\r\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\r\n",
    "#otherwise set what is needed\r\n",
    "if not 'Saving' in locals():\r\n",
    "    Saving = False\r\n",
    "if not 'Titles' in locals():\r\n",
    "    Titles = True\r\n",
    "if not 'Ledgends' in locals():\r\n",
    "    Ledgends = True\r\n",
    "if not 'FFormat' in locals():\r\n",
    "    FFormat = '.png'\r\n",
    "if not 'location' in locals():\r\n",
    "    #save location.  First one is for running on home PC, second for running on the work laptop.  May need to make a global change\r\n",
    "    #location = 'E:\\\\Documents\\\\Dan\\\\Code\\\\Prospectus\\\\Document\\\\Figures\\\\'\r\n",
    "    #location = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\github\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\r\n",
    "    location = 'E:\\\\Documents\\\\Dan\\\\Phd\\\\Play\\\\'\r\n",
    "\r\n",
    "#Standard cycle for collors and line styles\r\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\r\n",
    "plt.rc('axes', prop_cycle=default_cycler)\r\n",
    "my_cmap = plt.get_cmap('gray')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Extra Headers:\r\n",
    "import os as os\r\n",
    "import statistics as st\r\n",
    "import os as os\r\n",
    "import pandas as pd\r\n",
    "import random\r\n",
    "import multiprocessing\r\n",
    "from joblib import Parallel, delayed\r\n",
    "import time\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "Header = np.array(['T', 'X','Y','Z','R','Theta','Phi'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def getAcceleration(FileName):\r\n",
    "    try:\r\n",
    "        DataSet = np.genfromtxt(open(FileName,'r'), delimiter=',',skip_header=0)\r\n",
    "        if FileName[64:69] == 'Accel':\r\n",
    "            return [[FileName[61:],'x',DataSet[:,2]],[FileName[61:],'y',DataSet[:,3]],[FileName[61:],'z',DataSet[:,4]]]\r\n",
    "        else:\r\n",
    "            return [False,FileName,False]\r\n",
    "    except:\r\n",
    "        return [False,FileName,False]\r\n",
    "\r\n",
    "\r\n",
    "def makeStats(DataArray):\r\n",
    "    try:\r\n",
    "        Arange = 50\r\n",
    "        length = np.shape(DataArray[2])[0]\r\n",
    "        StdDev = np.zeros(length)\r\n",
    "        for j in range(length-Arange):\r\n",
    "            k = (length-1)-j\r\n",
    "            DataArray[2][k] = np.average(DataArray[2][k-Arange:k])\r\n",
    "            StdDev[k]=st.stdev(DataArray[2][k-Arange:k])\r\n",
    "        return [DataArray[0],DataArray[1],max(DataArray[2]),max(StdDev)]\r\n",
    "    except:\r\n",
    "        return ['','','','']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Inputs:\r\n",
    "folder1 = 'C:\\\\Users\\\\Hendrickson\\\\Desktop\\\\Phone Acceleration\\\\'\r\n",
    "folder2 = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\r\n",
    "\r\n",
    "files = os.listdir(folder2)\r\n",
    "\r\n",
    "Groups = 1\r\n",
    "GroupSize = 100\r\n",
    "\r\n",
    "RollingSize = 50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Pre Calculations\r\n",
    "\r\n",
    "num_cores = multiprocessing.cpu_count()\r\n",
    "if np.shape(files)[0] < GroupSize:\r\n",
    "    GroupSize = np.shape(files)[0]\r\n",
    "\r\n",
    "if Groups !=0:\r\n",
    "    files = random.sample(files,GroupSize*Groups-1)\r\n",
    "\r\n",
    "loops = int(float(np.size(files))/float(GroupSize))+1\r\n",
    "start = time.time()\r\n",
    "\r\n",
    "inverseRollingSize = 1 / RollingSize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    AllEvents=[]\r\n",
    "    Fails = []\r\n",
    "    for i in range(loops):\r\n",
    "        \r\n",
    "        AllAccels = Parallel(n_jobs=num_cores)(delayed(getAcceleration)(folder2+file) for file in files[i*GroupSize:((i+1)*GroupSize)])\r\n",
    "        Flattened = []\r\n",
    "        DataOnlyMatrix = []\r\n",
    "        for j in range(np.shape(AllAccels)[0]):\r\n",
    "            if AllAccels[j][0] == False :\r\n",
    "                if AllAccels[j][1][4:9] =='Accel':\r\n",
    "                    print(j,AllAccels[j][1])\r\n",
    "            else: \r\n",
    "                for k in range(3):\r\n",
    "                    Flattened.append(AllAccels[j][k])\r\n",
    "                    DataOnlyMatrix.append(AllAccels[j][k][2])\r\n",
    "        DataOnlyMatrix = np.matrix(DataOnlyMatrix)\r\n",
    "        \r\n",
    "        length = np.shape(DataOnlyMatrix)[1]\r\n",
    "        Weights = np.zeros((length,length))\r\n",
    "        \r\n",
    "        for j in range(length):\r\n",
    "            r = j+1\r\n",
    "            \r\n",
    "            if r < RollingSize:\r\n",
    "               ir = 1/ r\r\n",
    "               for k in range(r):\r\n",
    "                    Weights[j,k+1] = ir\r\n",
    "            else:\r\n",
    "                for k in range(RollingSize):\r\n",
    "                    Weights[j,r-RollingSize+k] = inverseRollingSize\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.8 GiB for an array with shape (60000, 60000) and data type float64",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-10f8997867e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataOnlyMatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mWeights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 26.8 GiB for an array with shape (60000, 60000) and data type float64"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "np.shape(DataOnlyMatrix)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(165, 60000)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "        \r\n",
    "        Events =  Parallel(n_jobs=num_cores)(delayed(makeStats)(DataArrays) for DataArrays in Flattened)\r\n",
    "        Events = np.matrix(Events)\r\n",
    "        if AllEvents ==[]:\r\n",
    "            AllEvents=Events\r\n",
    "        else:\r\n",
    "            try:\r\n",
    "                AllEvents=np.concatenate((AllEvents,Events), axis=0)\r\n",
    "            except:\r\n",
    "                Fails.append(Events)\r\n",
    "        print(str(i+1)+' of '+str(loops),'Time: '+ str((time.time()-start)/60.0))\r\n",
    "    \r\n",
    "    df = pd.DataFrame(data=AllEvents)\r\n",
    "    df.to_csv(folder1 + 'StatisticsReport.csv', sep=',', index = False, header=False,quotechar='\"')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "df = pd.DataFrame(data=AllEvents)\r\n",
    "df.to_csv(folder1 + 'StatisticsReport.csv', sep=',', index = False, header=False,quotechar='\"')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}